{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for Users Dataset\n",
      "One hot Encoding\n",
      "Splitting into Training and Test\n",
      "Feature Set\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 142301 entries, 0 to 142300\n",
      "Columns: 157 entries, age to wOSBrowser\n",
      "dtypes: float64(148), int64(9)\n",
      "memory usage: 170.5 MB\n",
      "building model now\n",
      "printing results without Sessions\n",
      "ROC for class 0 is: 0.72\n",
      "ROC for class 1 is: 0.694\n",
      "ROC for class 2 is: 0.602\n",
      "ROC for class 3 is: 0.601\n",
      "ROC for class 4 is: 0.569\n",
      "ROC for class 5 is: 0.614\n",
      "ROC for class 6 is: 0.57\n",
      "ROC for class 7 is: 0.616\n",
      "ROC for class 8 is: 0.642\n",
      "ROC for class 9 is: 0.621\n",
      "ROC for class 10 is: 0.647\n",
      "ROC for class 11 is: 0.504\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_td as td\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "\n",
    "# Work after Project Update1\n",
    "\n",
    "df_train = pd.read_csv('train_users_3.csv')\n",
    "df_sessions=pd.read_csv('sessions.csv')\n",
    "\n",
    "#replace NaN with -1\n",
    "av = df_train.age.values\n",
    "df_train['age'] = np.where(np.logical_or(av<14, av>100), -1, av)\n",
    "df_train.age.replace(np.nan, '-1' , inplace=True)\n",
    "df_train.gender.replace(np.nan, '-1' , inplace=True)\n",
    "df_train.first_affiliate_tracked.replace(np.nan, '-1' , inplace=True)\n",
    "\n",
    "'''df_sessions['id']=df_sessions['user_id']\n",
    "df_sessions=df_sessions.drop(['user_id'],axis=1)\n",
    "df_sessions.action=df_sessions.action.fillna(\"NaN\")\n",
    "df_sessions.action_type=df_sessions.action_type.fillna(\"NaN\")\n",
    "df_sessions.action_detail=df_sessions.action_detail.fillna(\"NaN\")\n",
    "df_sessions.device_type=df_sessions.device_type.fillna(\"NaN\")\n",
    "df_sessions.secs_elapsed=df_sessions.secs_elapsed.fillna(0.0)\n",
    "\n",
    "threshold = 100  # Remove items less than or equal to threshold\n",
    "vc = df_sessions['action'].value_counts()\n",
    "vals_to_remove = vc[vc <= threshold].index.values\n",
    "df_sessions['action'].loc[df_sessions['action'].isin(vals_to_remove)] = 'Other' \n",
    "'''\n",
    "#Feature Engineering\n",
    "print(\"Features for Users Dataset\")\n",
    "date_acc=pd.to_datetime(df_train['date_account_created'])\n",
    "\n",
    "df_train['year_account_created'] = date_acc.dt.year   \n",
    "df_train['month_account_created']=date_acc.dt.month\n",
    "df_train['day_account_created']=date_acc.dt.day\n",
    "\n",
    "val=df_train[\"timestamp_first_active\"].values\n",
    "year=[]\n",
    "month=[]\n",
    "day=[]\n",
    "hour=[]\n",
    "minutes=[]\n",
    "seconds=[]\n",
    "for x in val:\n",
    "    year.append(x.astype(str)[:4])\n",
    "    month.append(x.astype(str)[4:6])\n",
    "    day.append(x.astype(str)[6:8])\n",
    "    hour.append(x.astype(str)[8:10])\n",
    "    minutes.append(x.astype(str)[10:12])\n",
    "    seconds.append(x.astype(str)[12:14])\n",
    "\n",
    "df_train['year_first_active']=year\n",
    "df_train['month_first_active']=month\n",
    "df_train['day_first_active']=day\n",
    "df_train['hour_first_active']=hour\n",
    "df_train['minute_first_active']=minutes\n",
    "df_train['seconds_first_active']=seconds\n",
    "\n",
    "df_train['day_first_active']= pd.to_numeric(df_train['day_first_active'])\n",
    "df_train['month_first_active']= pd.to_numeric(df_train['month_first_active'])\n",
    "df_train['year_first_active']= pd.to_numeric(df_train['year_first_active'])\n",
    "df_train['hour_first_active']= pd.to_numeric(df_train['hour_first_active'])\n",
    "df_train['minute_first_active']= pd.to_numeric(df_train['minute_first_active'])\n",
    "df_train['seconds_first_active']= pd.to_numeric(df_train['seconds_first_active'])\n",
    "df_train['age']= pd.to_numeric(df_train['age'])\n",
    "\n",
    "\n",
    "df_train=df_train.drop('date_account_created',1)\n",
    "df_train=df_train.drop('timestamp_first_active',1)\n",
    "df_train=df_train.drop('date_first_booking',1)\n",
    "\n",
    "country_num_dic = {'NDF': 0, 'US': 1, 'other': 2, 'FR': 3, 'IT': 4, 'GB': 5, 'ES': 6, 'CA': 7, 'DE': 8, 'NL': 9, 'AU': 10, 'PT': 11}\n",
    "num_country_dic = {y:x for x,y in country_num_dic.items()}\n",
    "df_train['country_destination']= df_train['country_destination'].map(country_num_dic)\n",
    "\n",
    "'''f_act = df_sessions.action.value_counts().argsort()\n",
    "f_act_detail = df_sessions.action_detail.value_counts().argsort()\n",
    "f_act_type = df_sessions.action_type.value_counts().argsort()\n",
    "f_dev_type = df_sessions.device_type.value_counts().argsort()\n",
    "      \n",
    "print(\"Features for Sessions Dataset\")\n",
    "grpd_sessions=df_sessions.groupby(['id'])\n",
    "samples=[]\n",
    "cont=0\n",
    "for g in grpd_sessions:\n",
    "    if cont%10000 == 0:\n",
    "        print(\"%s of %s users' session data calculated\" %(cont, len(grpd_sessions)))\n",
    "    grp=g[1]\n",
    "    l=[]\n",
    "    l.append(g[0])\n",
    "    l.append(len(grp))\n",
    "    secs=grp.secs_elapsed.fillna(0).values\n",
    "    \n",
    "    c_act = [0] * len(f_act)\n",
    "    for i,v in enumerate(grp.action.values):\n",
    "        c_act[f_act[v]] += 1\n",
    "    _, c_act_uqc = np.unique(grp.action.values, return_counts=True)\n",
    "    c_act += [len(c_act_uqc), np.mean(c_act_uqc)]\n",
    "    l = l + c_act\n",
    "    \n",
    "    c_act_detail = [0] * len(f_act_detail)\n",
    "    for i,v in enumerate(grp.action_detail.values):\n",
    "        c_act_detail[f_act_detail[v]] += 1 \n",
    "    _, c_act_det_uqc = np.unique(grp.action_detail.values, return_counts=True)\n",
    "    c_act_detail += [len(c_act_det_uqc), np.mean(c_act_det_uqc)]\n",
    "    l = l + c_act_detail\n",
    "    \n",
    "    #action_type features\n",
    "    #(how many times each value occurs, numb of unique values, mean and std\n",
    "    #+ log of the sum of secs_elapsed for each value)\n",
    "    l_act_type = [0]*len(f_act_type)\n",
    "    c_act_type = [0]*len(f_act_type)\n",
    "    for i,v in enumerate(grp.action_type.values):\n",
    "        l_act_type[f_act_type[v]] += secs[i]   \n",
    "        c_act_type[f_act_type[v]] += 1  \n",
    "    l_act_type = np.log(1 + np.array(l_act_type)).tolist()\n",
    "    _, c_act_type_uqc = np.unique(grp.action_type.values, return_counts=True)\n",
    "    c_act_type += [len(c_act_type_uqc), np.mean(c_act_type_uqc)]\n",
    "    l = l + c_act_type + l_act_type    \n",
    "    \n",
    "    #device_type features\n",
    "    #(how many times each value occurs, numb of unique values, mean and std)\n",
    "    c_dev_type  = [0]*len(f_dev_type)\n",
    "    for i,v in enumerate(grp.device_type .values):\n",
    "        c_dev_type[f_dev_type[v]] += 1 \n",
    "    c_dev_type.append(len(np.unique(grp.device_type.values)))\n",
    "    _, c_dev_type_uqc = np.unique(grp.device_type.values, return_counts=True)\n",
    "    c_dev_type += [len(c_dev_type_uqc), np.mean(c_dev_type_uqc)]        \n",
    "    l = l + c_dev_type    \n",
    "    \n",
    "    secs_features=[0]*4\n",
    "    if(len(secs)>0):\n",
    "        secs_features[0]=np.log(1+np.sum(secs))\n",
    "        secs_features[1]=np.log(1+np.mean(secs))\n",
    "        secs_features[2]=np.log(1+np.median(secs))\n",
    "        secs_features[3]=np.log(1+np.std(secs))\n",
    "    l=l+secs_features\n",
    "    samples.append(l)\n",
    "    cont+=1\n",
    "\n",
    "col_names = []    \n",
    "for i in range(len(samples[0])-1):\n",
    "    col_names.append('secs_elapsed_' + str(i)) \n",
    "samples = np.array(samples)\n",
    "samp_ar = np.float_(samples[:, 1:])\n",
    "samp_id = samples[:, 0]   \n",
    "       \n",
    "df_agg_sess = pd.DataFrame(samp_ar, columns=col_names)\n",
    "df_agg_sess['id'] = samp_id\n",
    "df_agg_sess.index = df_agg_sess.id    \n",
    "\n",
    "#Merge Users and Sessions\n",
    "df_train = pd.merge(df_train, df_agg_sess,on ='id', how='left') \n",
    "df_train=df_train.fillna(-1)'''\n",
    "\n",
    "#One-Hot Encoding\n",
    "print(\"One hot Encoding\")\n",
    "categorical=['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', \n",
    "             'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "for x in categorical:\n",
    "    categorical_dummy=pd.get_dummies(df_train[x])\n",
    "    df_train=df_train.drop([x],axis=1)\n",
    "    df_train=pd.concat((df_train,categorical_dummy), axis=1)\n",
    "\n",
    "#Test-Train Split\n",
    "print(\"Splitting into Training and Test\")\n",
    "df_labels=df_train['country_destination']\n",
    "df_labels = label_binarize(df_labels, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "df_labels=pd.DataFrame(df_labels)\n",
    "df_train_labels=df_labels.loc[0:(np.floor(2*len(df_train)/3))]\n",
    "df_test_labels=df_labels.loc[(np.floor(2*len(df_train)/3)):]\n",
    "n_classes = df_labels.shape[1]\n",
    "      \n",
    "df_train=df_train.drop(\"id\",axis=1)\n",
    "df_test=df_train.loc[(np.floor(2*len(df_train)/3)):]\n",
    "df_train_new=df_train.loc[0:(np.floor(2*len(df_train)/3))]\n",
    "df_train_features=df_train_new.drop(\"country_destination\",axis=1)\n",
    "df_test_features=df_test.drop(\"country_destination\",axis=1)\n",
    "\n",
    "print(\"Feature Set\")\n",
    "df_train_features.info()\n",
    "print(\"building model now\")\n",
    "\n",
    "#Models - Decision Tree, Linear SVC\n",
    "#model=OneVsRestClassifier(DecisionTreeClassifier(min_samples_leaf=150)).fit(df_train_features,df_train_labels)\n",
    "\n",
    "#model = svm.LinearSVC(C=1).fit(df_train_features, df_train_labels)\n",
    "\n",
    "#gnb = GaussianNB()\n",
    "#model=OneVsRestClassifier(gnb).fit(df_train_features,df_train_labels)\n",
    "\n",
    "sgd=linear_model.SGDClassifier(loss=\"log\",alpha=.01, n_iter=150)\n",
    "model=OneVsRestClassifier(sgd).fit(df_train_features, df_train_labels)\n",
    "\n",
    "#rfc = RandomForestClassifier(n_estimators=15, max_depth=None,min_samples_split=1, random_state=0, min_samples_leaf=10)\n",
    "#model=(OneVsRestClassifier(rfc)).fit(df_train_features, df_train_labels)\n",
    "\n",
    "#etc=ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=1, random_state=0)\n",
    "#model=OneVsRestClassifier(etc).fit(df_train_features, df_train_labels)  \n",
    "\n",
    "#model=OneVsRestClassifier(AdaBoostClassifier(n_estimators=150, learning_rate=.5, random_state=0)).fit(df_train_features,df_train_labels)\n",
    "print(\"printing results without Sessions\")      \n",
    "#Multiclass    \n",
    "sgd=linear_model.SGDClassifier(loss=\"log\",alpha=.01, n_iter=150)\n",
    "model=OneVsRestClassifier(sgd).fit(df_train_features, df_train_labels)\n",
    "\n",
    "y_score=model.decision_function(df_test_features)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "y_test_labels=np.array(df_test_labels, dtype=pd.Series)\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_labels[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"ROC for class\",i ,\"is:\",roc_auc[i].round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results\n",
      "ROC for class 0 is: 0.824\n",
      "ROC for class 1 is: 0.781\n",
      "ROC for class 2 is: 0.619\n",
      "ROC for class 3 is: 0.592\n",
      "ROC for class 4 is: 0.547\n",
      "ROC for class 5 is: 0.55\n",
      "ROC for class 6 is: 0.465\n",
      "ROC for class 7 is: 0.444\n",
      "ROC for class 8 is: 0.532\n",
      "ROC for class 9 is: 0.421\n",
      "ROC for class 10 is: 0.487\n",
      "ROC for class 11 is: 0.446\n"
     ]
    }
   ],
   "source": [
    "#sgd=linear_model.SGDClassifier(loss=\"hinge\",alpha=.01, n_iter=250)\n",
    "#model=OneVsRestClassifier(sgd).fit(df_train_features, df_train_labels)\n",
    "model=OneVsRestClassifier(AdaBoostClassifier(n_estimators=150, learning_rate=.5, random_state=0)).fit(df_train_features,df_train_labels)\n",
    "\n",
    "print(\"printing results\")      \n",
    "#Multiclass           \n",
    "y_score=model.decision_function(df_test_features)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "y_test_labels=np.array(df_test_labels, dtype=pd.Series)\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_labels[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"ROC for class\",i ,\"is:\",roc_auc[i].round(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
